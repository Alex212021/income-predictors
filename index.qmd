---
title: "Predicting Income"
execute: 
  echo: false
  warning: false
---

**A person's income is determined by many factors, but which are the best predictors?**

To answer our question, we used the 2022 data from the General Social Survey. We modeled income, a continuous outcome variable, as a linear function of education (in years completed), race, sex and intelligence (as proxied by the "wordsum" test). As the table of regression coefficients below shows, individuals with higher incomes tend to be male, more educated, White and with higher "wordsum" scores. 

```{r}
# Load necessary packages

#| label: setup
#| message: FALSE
library(gssr)
library(brms)
library(tidybayes)
library(gtsummary)
library(tidyverse)
library(haven)
library(scales)
```

```{r}
#| label: cleaning
#| message: FALSE 

# Selecting the relevant columns and filtering out missing data

data(gss_all)

data_gss <- gss_all |>
  filter(year %in% c(2010, 2012, 2014, 2016, 2018, 2022)) |>
  select(conrinc, wordsum, race, educ, sex) |> 
  mutate(
    conrinc = as.numeric(conrinc),
    wordsum = as.numeric(wordsum),
    race = as_factor(race),
    educ = as.numeric(educ),
    sex = as_factor(sex)) |>
  drop_na()
```

```{r}
data_gss |> ggplot(aes(x = educ, y = conrinc))+
  geom_jitter(alpha = 0.1, color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "red", size = 1.5)+
  scale_y_continuous(labels = scales::comma) +
  labs(x = "Education (years completed)",
       y = "Personal income (dollars, inflation-adjusted)",
       title = "More Educated Tend To Have Higher Incomes")+
  theme_classic()
```


```{r}
#| label: model


# Fit the Bayesian linear regression model


model <- brm(conrinc ~ wordsum + race + educ + sex, 
             data = data_gss, 
             family = gaussian(),
             silent = 2,
             refresh = 0,
             seed = 123)

```

```{r}
#| label: table

# Display the coefficients in a gtsummary table


model |> 
  tbl_regression()


```

